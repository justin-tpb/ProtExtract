#!/bin/bash -l
source ~/.bashrc

# ProtExtract - a marker gene extractor
# Source: https://github.com/justin-tpb/ProtExtract/
# Author: Justin Teixeira Pereira Bassiaridis
# Date: 2024-10-19
# License: MIT

# Exit the script if an error appears or an unbound variable is called
set -eu

# Set version number
version="1.0.1"


# Help message for "-h" option
help_message() {
printf "\nProtExtract $version by Justin Teixeira Pereira Bassiaridis

ProtExtract uses DIAMOND to search for potential homologs of proteins within proteomes and extracts the sequence with the highest bit-score sum among all alignments with sequences from a query protein file.
It then performs a reciprocal DIAMOND search for verification, only keeping an extracted sequence if it realigns with a sequence from the same query protein file as before.
The extracted and verified sequences will be annotated with the filename of the query protein.
This tool was primarily designed to work with the 320 marker genes dataset from Strassert et al. 2021 (https://www.nature.com/articles/s41467-021-22044-z).
While it should work with other single-copy protein datasets, the results might be less accurate as the reciprocal verification depends on rich datasets.
It only extracts the best hit for each query protein file to avoid extracting paralogs.
If no homolog exists in the proteome, the best hit may be a paralog or analog.
Various information files about the found and missing proteins are created as well, including an output table.

Input:
A directory with protein files as queries, preferably with multiple homologs of the same protein per file for higher accuracy.
	The protein filenames will be treated as the protein names and must not contain spaces.
	If the protein sequences contain any gaps, copies without gaps will be created.
	The default directory is 'Proteins' and the default file extension is '.fasta'.
	A custom directory can be provided with the option -q and a custom file extension with -Q.
A directory with proteome files as subjects. Can be the same input folder, as long as the file extensions are different.
	The sequence headers should ideally not contain vertical bars '|'.
	The default directory is 'Proteomes' and the default file extension is '.fasta'.
	A custom directory can be provided with the option -s and a custom file extension with -S.

Important:
Working, input and output directories must not contain spaces!
ProtExtract requires an Anaconda environment called 'protextract' with DIAMOND, Python 3, Biopython and natsort.
You can use the option -c to do this automatically if you have Anaconda installed, or -C to use Mamba instead.

Options:
-q DIRECTORY: Protein (query) input directory. Defaults to 'Proteins'.
   Add proteins for which homologs are to be extracted here. Cannot be symlinks.
-Q STRING: Protein (query) file extension. Defaults to '.fasta'.
-s DIRECTORY: Proteome (subject) input directory. Defaults to 'Proteomes'.
   Add proteomes from which proteins are to be extracted here. Cannot be symlinks.
-S STRING: Proteome (subject) file extension. Defaults to '.fasta'.
-o DIRECTORY: Output directory. Defaults to 'Output_<evalue>_<coverage>_<pidentity>'.
-O STRING: Output directory suffix, appended with an underscore. Defaults to no suffix.
-t INTEGER: Number of threads used by DIAMOND. Defaults to all available cores.
-m STRING: Sensitivity mode for DIAMOND. Defaults to 'default'.
   Available modes: 'fast', 'mid-sensitive', 'sensitive', 'more-sensitive', 'very-sensitive', 'ultra-sensitive'
-E STRING: Maximum allowed E-value for DIAMOND. Defaults to '1e-20'.
-%% INTEGER: Minimum required percentage of query and subject coverage for DIAMOND. Defaults to '50'.
-p INTEGER: Minimum required percentage of identical positions for DIAMOND. Defaults to '20'.
-f: Force overwrite of existing output files.
-c: Create the required conda environment with Anaconda:
    conda create -n protextract -c conda-forge -c bioconda python biopython natsort diamond
-C: Create the required conda environment with Mamba:
    mamba create -n protextract -c conda-forge -c bioconda python biopython natsort diamond
-v: Display the version number.
-h: Show this help message.\n\n"
}


# Parse command line options
parse_options() {
	while getopts :q:Q:s:S:o:O:m:t:E:%:p:fcCvh flag
	do
		case "$flag" in
			q) queries_dir="$OPTARG";;
			Q) queries_extension="${OPTARG#.}";;
			s) subjects_dir="$OPTARG";;
			S) subjects_extension="${OPTARG#.}";;
			o) output_dir="$OPTARG";;
			O) output_suffix="$OPTARG";;
			t) threads="$OPTARG";;
			m) sensitivity="$OPTARG";;
			E) evalue="$OPTARG";;
			%) coverage="$OPTARG";;
			p) pident="$OPTARG";;
			f) force_overwrite=true;;
			c) printf "\nExecuting: conda create -n protextract -c conda-forge -c bioconda python biopython natsort diamond\n\n"
			conda create -n protextract -c conda-forge -c bioconda python biopython natsort diamond
			exit 0;;
			C) printf "\nExecuting: mamba create -n protextract -c conda-forge -c bioconda python biopython natsort diamond\n\n"
			mamba create -n protextract -c conda-forge -c bioconda python biopython natsort diamond
			exit 0;;
			v) printf "\nProtExtract $version by Justin Teixeira Pereira Bassiaridis\n\n"
			exit 0;;
			h) help_message 
			exit 0;;
			\?) printf "\nError: Invalid option: -$OPTARG\n\n"
			exit 1;;
			:) printf "\nError: option -$OPTARG requires an argument!\n\n"
			exit 1;;
		esac
	done
}


# Main ProtExtract function
ProtExtract() {
	## Check if required Python scripts exist
	# Define the path to the directory containing the scripts
	python_scripts_dir="$(dirname "$0")/ProtExtract_scripts/"

	# List of scripts to be checked for existence
	python_scripts=("extract_and_rename_sequences.py" "generate_protein_table.py" "keep_verified_sequences.py" "merge_fasta_files.py")

	# Loop through the list of scripts and check if they exist
	for script_name in "${python_scripts[@]}"; do
		if [ ! -f "$python_scripts_dir/$script_name" ]; then
			printf "\nMissing '$script_name'!\nPlease download it from 'https://github.com/justin-tpb/ProtExtract/tree/main/ProtExtract_scripts'"
			printf " and put it into a folder called 'ProtExtract_scripts' next to the ProtExtract main script.\n\n"
			exit 1
		fi
	done


	## Input handling
	# Set the path to the queries (proteins) with absolute path if not provided
	queries_dir="${queries_dir:-"$(pwd)/Proteins/"}"
	[[ "$queries_dir" != /* ]] && queries_dir="$(pwd)/$queries_dir"
	queries_dir="${queries_dir%/}"

	# Set the path to the subjects (proteomes) with absolute path if not provided
	subjects_dir="${subjects_dir:-"$(pwd)/Proteomes/"}"
	[[ "$subjects_dir" != /* ]] && subjects_dir="$(pwd)/$subjects_dir"
	subjects_dir="${subjects_dir%/}"

	# Check if input folders exist
	if [[ ! -d "$queries_dir" ]]; then
		printf "\nError: Directory '$queries_dir/' does not exist.\nPlease use the option -q to provide a valid protein directory.\n\n"
		exit 1
	elif [[ ! -d "$subjects_dir" ]]; then
		printf "\nError: Directory '$subjects_dir/' does not exist.\nPlease use the option -s to provide a valid proteome directory.\n\n"
		exit 1
	fi

	# Set the default file extensions if not provided
	queries_extension=".${queries_extension:-fasta}"
	subjects_extension=".${subjects_extension:-fasta}"

	# Check if input files exist using find
	if [[ -z $(find "$queries_dir" -maxdepth 1 -name "*$queries_extension" -type f) ]]; then
		printf "\nError: No '$queries_extension' files found in '$queries_dir/'.\nPlease double-check the file extension.\n\n"
		exit 1
	elif [[ -z $(find "$subjects_dir" -maxdepth 1 -name "*$subjects_extension" -type f) ]]; then
		printf "\nError: No '$subjects_extension' files found in '$subjects_dir/'.\nPlease double-check the file extension.\n\n"
		exit 1
	fi

	# Create a sorted list of all queries and subjects in the provided directories by using a wildcard in front of the file type
	queries=($(printf "%s\n" "$queries_dir/"*"$queries_extension" | sort -Vf))
	subjects=($(printf "%s\n" "$subjects_dir/"*"$subjects_extension" | sort -Vf))


	## Options handling
	# Set the number of threads for DIAMOND
	threads="${threads:-all available cores}"
	if [[ "$threads" == "all available cores" ]]; then
		threads_option=""
	else
		threads_option="--threads $threads"
	fi
	
	# Set the sensitivity of DIAMOND
	sensitivity="${sensitivity:-default}"
	if [[ "$sensitivity" == "default" ]]; then
		sensitivity_option=""
	else
		sensitivity_option="--$sensitivity"
	fi

	# Set the maximum allowed e-value for DIAMOND if not provided
	evalue="${evalue:-1e-20}"

	# Set the minimum required coverage for DIAMOND if not provided
	coverage="${coverage:-50}"

	# Set the minimum required percent identity for DIAMOND if not provided
	pident="${pident:-20}"


	## Output handling
	# Set the output directory with absolute path if not specified
	output_dir="${output_dir:-"$(pwd)/Output_${evalue}_cov${coverage}_pid$pident/"}"
	[[ "$output_dir" != /* ]] && output_dir="$(pwd)/$output_dir"
	output_suffix="${output_suffix:-}"
	[[ "$output_suffix" ]] && output_dir="${output_dir%/}_$output_suffix"

	# Set force overwrite to false if unset
	force_overwrite=${force_overwrite:=false}

	# Check if output folder already exists and ask for overwrite confirmation
	if [[ -d "$output_dir" && "$force_overwrite" == false ]]; then
		echo
		read -p "Output directory '$output_dir/' already exists. Overwrite existing files? (y/n): " choice
		case "$choice" in
			y|Y) ;;
			*) printf "\nExiting ProtExtract. Please rename the existing output folder or specify a new one.\n\n"
			   exit 1;;
		esac
	fi

	# Set all needed output subdirectories and create them
	working_dir="$output_dir/Working_directory/"
	query_working_dir="$working_dir/Protein_data/"
	subject_working_dir="$working_dir/Subject_data/"
	extracted_fasta_dir="$output_dir/Proteins/Sequences/"
	extracted_summary_dir="$output_dir/Proteins/Summaries/"
	mkdir -p "$query_working_dir" "$subject_working_dir" "$extracted_fasta_dir" "$extracted_summary_dir"

	## Print start message
	printf "\n\nProtExtract $version by Justin Teixeira Pereira Bassiaridis\n\n\n"
	printf "********** Settings **********\n\n"
	printf "Proteins (queries): $queries_dir/"*"$queries_extension\n"
	printf "Proteomes (subjects): $subjects_dir/"*"$subjects_extension\n"
	printf "Output directory: $output_dir/\n"
	printf "Number of threads: ${threads:-'all available cores'}\n"
	printf "Sensitivity mode: $sensitivity\n"
	printf "Maximum allowed E-value: $evalue\n"
	printf "Minimum required coverage: $coverage%%\n"
	printf "Minimum required percent identity: $pident%%\n\n\n"


	## Remove any existing gaps from the query protein sequences
	# Read the query protein sequences into one continuous string of amino acids
	sequence=$(grep -v ">" "${queries[@]}" | sed "s/.*://g" | tr -d "\n")

	# Check if any gaps exist within query protein sequences
	if [[ $sequence == *-* ]]; then
		# Print gap information
		printf "********** Gap detection **********\n\n"
		printf "Gaps were detected within the query protein sequences.\n\n"
		printf "Gapless copies will be created in the working directory.\n\n\n"

		# Set gapless query protein directory and create it
		gapless_queries_dir="$query_working_dir/Gapless_proteins/"
		mkdir -p "$gapless_queries_dir" 

		# Copy query proteins into the new directory
		cp "${queries[@]}" "$gapless_queries_dir"

		# Set queries to gapless queries
		queries_dir="$gapless_queries_dir"
		queries=($(printf "%s\n" "$gapless_queries_dir/"*"$queries_extension" | sort -Vf))

		# Remove any gaps from the copies
		sed -i '/^>/! s/-//g' "${queries[@]}"
	fi


	## Create list with all query protein names based on filenames for final verification
	# Set query filename list
	query_filenames="$query_working_dir/protein_filenames.txt"

	# For loop to turn all protein filenames into a list, sorted alphabetically and case-insensitive
	for file in "$queries_dir/"*"$queries_extension"; do echo $(basename "$file" "$queries_extension"); done | sort -Vf > "$query_filenames"


	## Create a single query protein fasta by merging all query protein files reciprocal blast
	# Set merged query proteins
	query_files_merged="$query_working_dir/protein_files.merged.fasta"

	# Run "merge_fasta_files.py" to merge all query protein files into a single file (requires biopython and natsort)
	# The filename of each file will be added to the front of each sequence header within
	printf "********** Preparation for reciprocal DIAMOND search **********\n\n"
	printf "Merging all protein files into a single file.\n\n"
	python3 "$python_scripts_dir/merge_fasta_files.py" "$queries_dir" "$query_files_merged"
	
	# Set query protein database
	query_db="${query_files_merged%.fasta}"

	# Create a DIAMOND database for the merged query proteins file
	printf "Creating a DIAMOND database for the merged protein file.\n\n\n"
	diamond makedb --in "$query_files_merged" --db "$query_db" --quiet $threads_option


	### Main task, inluding protein identification, extraction and verification with DIAMOND, AWK and Python
	## Best protein hit identification using DIAMOND and AWK
	# Loop through each subject
	for subject in "${subjects[@]}"; do
		# Print subject processing
		printf "********** Processing $(basename "$subject") **********\n\n"

		# Set the subject output name
		subject_name=$(basename "$subject" "$subjects_extension")

		# Set and create the subject and protein extraction output directories
		subject_dir="$output_dir/Subjects/$subject_name/"
		extraction_dir="$subject_dir/Extraction/"
		extraction_diamond_dir="$extraction_dir/DIAMOND/"
		mkdir -p "$extraction_diamond_dir"

		# Set subject database
		subject_db="$subject_working_dir/$subject_name"

		# Initialize the file storing the subject sequence IDs of the best hits
		best_hits="$extraction_diamond_dir/best_hits.txt"
		> "$best_hits"

		# Create a DIAMOND database for each subject
		printf "Creating a DIAMOND database for '$(basename "$subject")'.\n\n"
		diamond makedb --in "$subject" --db "$subject_db" --quiet $threads_option
		
		# Print DIAMOND search text
		printf "Running DIAMOND to identify the proteins to extract from '$(basename "$subject")':\n"

		# Loop through each query
		for query in "${queries[@]}"; do
			# Set the DIAMOND output filename
			diamond_out="$extraction_diamond_dir/$(basename "$query" "$queries_extension").tsv"

			# Run DIAMOND in user-defined sensitivity mode with the protein name as the output filename
			# DIAMOND will only show the best hit for each query sequence, with a maximum e-value and minimum coverage and percent identity
			# \33[2K\r makes the terminal output overwrite the current line
			printf "\33[2K\rRunning DIAMOND with the query '$(basename "$query")'."
			diamond blastp --query "$query" --db "$subject_db" --out "$diamond_out" --quiet $threads_option $sensitivity_option \
			--max-target-seqs 1 --evalue "$evalue" --query-cover "$coverage" --subject-cover "$coverage" --id "$pident" \
			--outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovhsp scovhsp

			# Extract the query name from the file path, removing the extension
			query_name=$(basename "$query" "$queries_extension")

			# AWK script to append the query name and subject sequence ID with the highest bit-score sum (i.e. the best hit) to a file
			# It prints "missing" instead of a sequence ID if no hits were found
			awk -v qname="$query_name" '{
				sum[$2] += $12
			}
			END {
				max = 0
				for (hit in sum) {
					if (sum[hit] > max) {
						max = sum[hit]
						besthit = hit
					}
				}
				if (max) {
					print qname "\t" besthit
				} else {
					print qname "\t" "missing"
				}
			}' "$diamond_out" >> "$best_hits"
		done
		# Print query search finish text
		printf "\33[2K\rDone!"


		## Start of protein extraction using AWK and Python
		# Set the extracted protein output filenames
		unverified_proteins_fasta="$extraction_dir/$subject_name.unverified_proteins.fasta"
		unverified_proteins_summary="$extraction_dir/$subject_name.unverified_summary.txt"

		# AWK script to sort the best protein hit list alphabetically and case-insensitive
		# It then pipes the output into another AWK script which adds "duplicate" to the third column of duplicated sequences
		printf "\n\nWriting information about the best hits to '$(basename "$unverified_proteins_summary")'.\n\n"
		awk '{
			print $1, $2
		}' "$best_hits" |
		sort -Vf |
		awk '{
			if ($2 == "missing") {
				print
			} else {
				count[$2]++
				if (count[$2] > 1) {
					$3 = "duplicate"
				}
				print
			}
		}' > "$unverified_proteins_summary"

		# Remove the original best hit file
		rm "$best_hits"

		# AWK script to check if any proteins were found and set corresponding variable
		proteins_found=$(awk '
			$2 != "missing" {
				found = 1
				exit
			}
		END {
			print (found ? "true" : "false")
		}' "$unverified_proteins_summary")

		# Skip to next subject if no proteins were found
		if [[ "$proteins_found" == false ]]; then
			printf "No proteins were found in '$(basename "$subject")'. Skipping the reciprocal verification.\n\n\n"
			cp "$unverified_proteins_summary" "$extracted_summary_dir/$(basename "$unverified_proteins_summary" .unverified.summary.txt).summary.txt"
			continue
		fi

		# Run "extract_and_rename_seqs.py" to extract the sequences of the best hits (requires biopython and natsort)
		printf "Extracting the best hits to '$(basename "$unverified_proteins_fasta")'.\n\n"
		python3 "$python_scripts_dir/extract_and_rename_sequences.py" "$subject" "$unverified_proteins_summary" "$unverified_proteins_fasta"


		## Start of verification by reciprocal search using DIAMOND, AWK and Python
		# Set and create the verification directories
		verification_dir="$subject_dir/Verification/"
		mkdir -p "$verification_dir"

		# Set the verified proteins output filenames
		verified_proteins_fasta="$subject_dir/$subject_name.proteins.fasta"
		verified_proteins_summary="$subject_dir/$subject_name.summary.txt"
		verified_proteins_reciprocal="$verification_dir/$subject_name.reciprocal.txt"

		# Set the DIAMOND output filename
		diamond_reciprocal_out="$verification_dir/$subject_name.reciprocal.tsv"

		# Run reciprocal blast search with DIAMOND in user-defined sensitivity mode
		# DIAMOND will only show the best hit for each query sequence, with a maximum e-value and minimum coverage and percent identity
		printf "Running a reciprocal DIAMOND search to verify the extracted proteins in '$(basename "$unverified_proteins_fasta")'.\n\n"
		diamond blastp --query "$unverified_proteins_fasta" --db "$query_db" --out "$diamond_reciprocal_out" --quiet $threads_option $sensitivity_option \
		--max-target-seqs 1 --evalue "$evalue" --query-cover "$coverage" --subject-cover "$coverage"  --id "$pident" \
		--outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovhsp scovhsp

		# AWK script that checks if the protein names within query and subject sequence IDs match
			# and outputs the protein name with either "matches" or "does_not_match"
		printf "Writing information about the reciprocal verification to '$(basename "$verified_proteins_reciprocal")'.\n\n"
		awk '{
			split($1, query, "|")
			split($2, subject, "|")
			if (query[1] == subject[1]) {
				print query[1], "matches"
			} else {
				print query[1], "does_not_match"
			}
		}' "$diamond_reciprocal_out" > "$verified_proteins_reciprocal"
		
		# AWK script that outputs which proteins were found and which are missing after verification
		awk -v filenames="$query_filenames" '
		BEGIN {
			while (getline < filenames)
				proteins[$1]
		}
		{
			split($1, query, "|")
			split($2, subject, "|")
			if (query[1] == subject[1]) {
				found[query[1]] = $1
			}
		}
		END {
			for (protein in proteins) {
				if (protein in found) {
					print found[protein]
				} else {
					print protein, "missing"
				}
			}
		}' "$diamond_reciprocal_out" | sort -Vf | sed 's/|/ /' > "$verified_proteins_summary"

		# Copy final summary to collective folder
		cp "$verified_proteins_summary" "$extracted_summary_dir/$(basename "$verified_proteins_summary")"

		# Run "keep_verified_sequences.py" to keep only sequences verified by reciprocal blast (requires biopython)
		# Verified sequences are taken from "$verified_proteins_reciprocal" and piped to the Python script via stdin
		grep "matches" "$verified_proteins_reciprocal" | sed 's/matches//g' |
		python3 "$python_scripts_dir/keep_verified_sequences.py" "$unverified_proteins_fasta" - "$verified_proteins_fasta"

		# Print number of verified proteins
		verified_proteins_count=$(grep ">" "$verified_proteins_fasta" | wc -l)
		printf "$verified_proteins_count proteins were successfully extracted and verified.\n\n"

		# Print final subject file locations
		printf "The final FASTA file with the extracted and verified proteins can be found here:\n"
		printf "${subject_dir%/}/$(basename "$verified_proteins_fasta")\n\n"
		printf "The final summary file with information about found and missing proteins can be found here:\n"
		printf "${subject_dir%/}/$(basename "$verified_proteins_summary")\n\n\n"

		# Copy final extracted protein sequences to collective folder
		cp "$verified_proteins_fasta" "$extracted_fasta_dir/$(basename "$verified_proteins_fasta")"
	done


	## Generating protein summary
	# Set the protein summary table filename
	protein_table="$output_dir/Proteins/protein_summary.tsv"

	# Run "generate_protein_table.py" to generate a summary table with information about found and missing proteins in the proteomes
	python3 "$python_scripts_dir/generate_protein_table.py" "$extracted_summary_dir" "$protein_table"

	# Remove ".summary.txt" from the filenames within the protein summary table
	sed -i 's/.summary.txt//g' "$protein_table"

	## Print finish message
	printf "********** ProtExtract finished **********\n\n"
	printf "All FASTA files with the extracted and verified proteins can be found here:\n"
	printf "$extracted_fasta_dir\n\n"
	printf "All individual summary files with information about found and missing proteins can be found here:\n"
	printf "$extracted_summary_dir\n\n"
	printf "A summary table with information about all found and missing proteins can be found here:\n"
	printf "$protein_table\n\n"
	printf "Runtime: $(($SECONDS / 3600))h $((($SECONDS / 60) % 60))min $(($SECONDS % 60))s\n\n\n"

	# Trap to move log file on exit
	trap "mv ProtExtract.log '$output_dir'" EXIT
}


# Activate the conda environment and call functions, printing stdout and stderr to both the terminal and a log file
parse_options "$@"
conda activate protextract
ProtExtract |& tee ProtExtract.log
conda deactivate
